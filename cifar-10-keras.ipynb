{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to unpickle the dataset\n",
    "def unpickle_all_data(directory):\n",
    "    \n",
    "    # Initialize the variables\n",
    "    train = dict()\n",
    "    test = dict()\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    \n",
    "    # Iterate through all files that we want, train and test\n",
    "    # Train is separated into batches\n",
    "    for filename in listdir(directory):\n",
    "        if isfile(join(directory, filename)):\n",
    "            \n",
    "            # The train data\n",
    "            if 'data_batch' in filename:\n",
    "                print('Handing file: %s' % filename)\n",
    "                \n",
    "                # Opent the file\n",
    "                with open(directory + '/' + filename, 'rb') as fo:\n",
    "                    data = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "                if 'data' not in train:\n",
    "                    train['data'] = data[b'data']\n",
    "                    train['labels'] = np.array(data[b'labels'])\n",
    "                else:\n",
    "                    train['data'] = np.concatenate((train['data'], data[b'data']))\n",
    "                    train['labels'] = np.concatenate((train['labels'], data[b'labels']))\n",
    "            # The test data\n",
    "            elif 'test_batch' in filename:\n",
    "                print('Handing file: %s' % filename)\n",
    "                \n",
    "                # Open the file\n",
    "                with open(directory + '/' + filename, 'rb') as fo:\n",
    "                    data = pickle.load(fo, encoding='bytes')\n",
    "                \n",
    "                test['data'] = data[b'data']\n",
    "                test['labels'] = data[b'labels']\n",
    "    \n",
    "    # Manipulate the data to the propper format\n",
    "    for image in train['data']:\n",
    "        train_x.append(np.transpose(np.reshape(image,(3, 32,32)), (1,2,0)))\n",
    "    train_y = [label for label in train['labels']]\n",
    "    \n",
    "    for image in test['data']:\n",
    "        test_x.append(np.transpose(np.reshape(image,(3, 32,32)), (1,2,0)))\n",
    "    test_y = [label for label in test['labels']]\n",
    "    \n",
    "    # Transform the data to np array format\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    test_x = np.array(test_x)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handing file: data_batch_1\n",
      "Handing file: data_batch_2\n",
      "Handing file: data_batch_3\n",
      "Handing file: data_batch_4\n",
      "Handing file: data_batch_5\n",
      "Handing file: test_batch\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = unpickle_all_data(os.getcwd() + '/cifar-10-batches-py/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000,)\n",
      "(10000, 32, 32, 3)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# Transofrm them to a float32 type\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize the input \n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# One-hot Encoding\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "\n",
    "# Create the model\n",
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "batch_size = 64\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt_rms, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 1.9264 - acc: 0.4339 - val_loss: 1.9785 - val_acc: 0.4608\n",
      "Epoch 2/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.4268 - acc: 0.5939 - val_loss: 1.4659 - val_acc: 0.5449\n",
      "Epoch 3/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.2928 - acc: 0.6386 - val_loss: 1.0575 - val_acc: 0.6661\n",
      "Epoch 4/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1501 - acc: 0.6741 - val_loss: 0.9429 - val_acc: 0.7120\n",
      "Epoch 5/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1266 - acc: 0.6917 - val_loss: 0.9799 - val_acc: 0.7139\n",
      "Epoch 6/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0450 - acc: 0.7146 - val_loss: 0.9205 - val_acc: 0.7292\n",
      "Epoch 7/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0558 - acc: 0.7218 - val_loss: 0.9595 - val_acc: 0.7374\n",
      "Epoch 8/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0140 - acc: 0.7342 - val_loss: 0.9655 - val_acc: 0.7206\n",
      "Epoch 9/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9960 - acc: 0.7409 - val_loss: 0.8454 - val_acc: 0.7576\n",
      "Epoch 10/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9881 - acc: 0.7492 - val_loss: 1.2275 - val_acc: 0.7452\n",
      "Epoch 11/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9574 - acc: 0.7508 - val_loss: 1.0257 - val_acc: 0.7299\n",
      "Epoch 12/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9490 - acc: 0.7594 - val_loss: 0.8506 - val_acc: 0.7690\n",
      "Epoch 13/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9345 - acc: 0.7642 - val_loss: 0.8832 - val_acc: 0.7471\n",
      "Epoch 14/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9388 - acc: 0.7667 - val_loss: 0.8247 - val_acc: 0.7904\n",
      "Epoch 15/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9030 - acc: 0.7736 - val_loss: 0.8651 - val_acc: 0.7895\n",
      "Epoch 16/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9012 - acc: 0.7762 - val_loss: 1.1637 - val_acc: 0.7042\n",
      "Epoch 17/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9026 - acc: 0.7784 - val_loss: 0.8352 - val_acc: 0.7655\n",
      "Epoch 18/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8942 - acc: 0.7801 - val_loss: 0.8304 - val_acc: 0.7770\n",
      "Epoch 19/100\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8994 - acc: 0.7822 - val_loss: 0.7063 - val_acc: 0.8119\n",
      "Epoch 20/100\n",
      "781/781 [==============================] - 28s 35ms/step - loss: 0.9067 - acc: 0.7831 - val_loss: 0.7836 - val_acc: 0.7933\n",
      "Epoch 21/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.8925 - acc: 0.7855 - val_loss: 0.7694 - val_acc: 0.7900\n",
      "Epoch 22/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 1.0345 - acc: 0.7750 - val_loss: 0.9452 - val_acc: 0.7627\n",
      "Epoch 23/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.9225 - acc: 0.7820 - val_loss: 0.8113 - val_acc: 0.7990\n",
      "Epoch 24/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.9010 - acc: 0.7844 - val_loss: 0.9024 - val_acc: 0.7760\n",
      "Epoch 25/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9012 - acc: 0.7896 - val_loss: 0.7940 - val_acc: 0.8079\n",
      "Epoch 26/100\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 0.8914 - acc: 0.7917 - val_loss: 0.8341 - val_acc: 0.8136\n",
      "Epoch 27/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.8776 - acc: 0.7940 - val_loss: 0.8117 - val_acc: 0.7943\n",
      "Epoch 28/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.8737 - acc: 0.7952 - val_loss: 0.6722 - val_acc: 0.8311\n",
      "Epoch 29/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.8651 - acc: 0.7971 - val_loss: 0.9499 - val_acc: 0.7461\n",
      "Epoch 30/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.8501 - acc: 0.7996 - val_loss: 0.8990 - val_acc: 0.7618\n",
      "Epoch 31/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.8483 - acc: 0.8024 - val_loss: 0.7273 - val_acc: 0.8199\n",
      "Epoch 32/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8557 - acc: 0.8011 - val_loss: 0.9088 - val_acc: 0.7771\n",
      "Epoch 33/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.8450 - acc: 0.8033 - val_loss: 0.6650 - val_acc: 0.8357\n",
      "Epoch 34/100\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 0.8385 - acc: 0.8057 - val_loss: 0.8281 - val_acc: 0.7980\n",
      "Epoch 35/100\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8273 - acc: 0.8066 - val_loss: 0.6629 - val_acc: 0.8388\n",
      "Epoch 36/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.8384 - acc: 0.8052 - val_loss: 0.8991 - val_acc: 0.7794\n",
      "Epoch 37/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.8217 - acc: 0.8055 - val_loss: 0.8087 - val_acc: 0.8058\n",
      "Epoch 38/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.8166 - acc: 0.8095 - val_loss: 0.8140 - val_acc: 0.7936\n",
      "Epoch 39/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.8044 - acc: 0.8129 - val_loss: 0.8359 - val_acc: 0.7936\n",
      "Epoch 40/100\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8160 - acc: 0.8107 - val_loss: 0.7707 - val_acc: 0.8238\n",
      "Epoch 41/100\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.7986 - acc: 0.8126 - val_loss: 0.7300 - val_acc: 0.8119\n",
      "Epoch 42/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.8007 - acc: 0.8113 - val_loss: 0.6610 - val_acc: 0.8438\n",
      "Epoch 43/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.7898 - acc: 0.8133 - val_loss: 0.7420 - val_acc: 0.8122\n",
      "Epoch 44/100\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.7765 - acc: 0.8146 - val_loss: 0.7342 - val_acc: 0.8168\n",
      "Epoch 45/100\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 0.7770 - acc: 0.8127 - val_loss: 0.6951 - val_acc: 0.8351\n",
      "Epoch 46/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.7662 - acc: 0.8149 - val_loss: 0.8334 - val_acc: 0.7898\n",
      "Epoch 47/100\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.7482 - acc: 0.8172 - val_loss: 0.8479 - val_acc: 0.7839\n",
      "Epoch 48/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.7255 - acc: 0.8204 - val_loss: 0.7543 - val_acc: 0.8166\n",
      "Epoch 49/100\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.7217 - acc: 0.8207 - val_loss: 0.7085 - val_acc: 0.8299\n",
      "Epoch 50/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.7218 - acc: 0.8202 - val_loss: 0.8054 - val_acc: 0.8040\n",
      "Epoch 51/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.7132 - acc: 0.8245 - val_loss: 0.7387 - val_acc: 0.8219\n",
      "Epoch 52/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.7072 - acc: 0.8228 - val_loss: 0.6327 - val_acc: 0.8479\n",
      "Epoch 53/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.7037 - acc: 0.8247 - val_loss: 0.7053 - val_acc: 0.8288\n",
      "Epoch 54/100\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.7011 - acc: 0.8246 - val_loss: 0.7103 - val_acc: 0.8266\n",
      "Epoch 55/100\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 0.6868 - acc: 0.8264 - val_loss: 0.7184 - val_acc: 0.8222\n",
      "Epoch 56/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6900 - acc: 0.8262 - val_loss: 0.7669 - val_acc: 0.8103\n",
      "Epoch 57/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6757 - acc: 0.8296 - val_loss: 0.6941 - val_acc: 0.8252\n",
      "Epoch 58/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.6781 - acc: 0.8279 - val_loss: 0.7094 - val_acc: 0.8250\n",
      "Epoch 59/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.6662 - acc: 0.8306 - val_loss: 0.6953 - val_acc: 0.8285\n",
      "Epoch 60/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6611 - acc: 0.8313 - val_loss: 0.9684 - val_acc: 0.7692\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6669 - acc: 0.8292 - val_loss: 0.6998 - val_acc: 0.8302\n",
      "Epoch 62/100\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.6584 - acc: 0.8322 - val_loss: 0.7070 - val_acc: 0.8193\n",
      "Epoch 63/100\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.6559 - acc: 0.8331 - val_loss: 0.7513 - val_acc: 0.8049\n",
      "Epoch 64/100\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.6437 - acc: 0.8337 - val_loss: 0.6226 - val_acc: 0.8464\n",
      "Epoch 65/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6519 - acc: 0.8322 - val_loss: 0.6845 - val_acc: 0.8297\n",
      "Epoch 66/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.6413 - acc: 0.8357 - val_loss: 0.7091 - val_acc: 0.8183\n",
      "Epoch 67/100\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.6370 - acc: 0.8360 - val_loss: 0.6495 - val_acc: 0.8391\n",
      "Epoch 68/100\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 0.6385 - acc: 0.8331 - val_loss: 0.7629 - val_acc: 0.8136\n",
      "Epoch 69/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.6288 - acc: 0.8387 - val_loss: 0.6941 - val_acc: 0.8252\n",
      "Epoch 70/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6298 - acc: 0.8393 - val_loss: 0.8223 - val_acc: 0.7900\n",
      "Epoch 71/100\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.6259 - acc: 0.8393 - val_loss: 0.6779 - val_acc: 0.8291\n",
      "Epoch 72/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.6265 - acc: 0.8382 - val_loss: 0.6624 - val_acc: 0.8341\n",
      "Epoch 73/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.6199 - acc: 0.8409 - val_loss: 0.6108 - val_acc: 0.8525\n",
      "Epoch 74/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.6205 - acc: 0.8405 - val_loss: 0.6665 - val_acc: 0.8331\n",
      "Epoch 75/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6160 - acc: 0.8414 - val_loss: 0.6087 - val_acc: 0.8540\n",
      "Epoch 76/100\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 0.6152 - acc: 0.8407 - val_loss: 0.7437 - val_acc: 0.8108\n",
      "Epoch 77/100\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 0.6088 - acc: 0.8441 - val_loss: 0.6997 - val_acc: 0.8243\n",
      "Epoch 78/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6123 - acc: 0.8417 - val_loss: 0.7385 - val_acc: 0.8208\n",
      "Epoch 79/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.6118 - acc: 0.8401 - val_loss: 0.6961 - val_acc: 0.8167\n",
      "Epoch 80/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6069 - acc: 0.8416 - val_loss: 0.6146 - val_acc: 0.8499\n",
      "Epoch 81/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6064 - acc: 0.8423 - val_loss: 0.6525 - val_acc: 0.8441\n",
      "Epoch 82/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6100 - acc: 0.8427 - val_loss: 0.6673 - val_acc: 0.8358\n",
      "Epoch 83/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6046 - acc: 0.8443 - val_loss: 0.7060 - val_acc: 0.8251\n",
      "Epoch 84/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6038 - acc: 0.8437 - val_loss: 0.6208 - val_acc: 0.8423\n",
      "Epoch 85/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.6008 - acc: 0.8458 - val_loss: 0.6940 - val_acc: 0.8328\n",
      "Epoch 86/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6038 - acc: 0.8442 - val_loss: 0.6143 - val_acc: 0.8491\n",
      "Epoch 87/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.6000 - acc: 0.8470 - val_loss: 0.6306 - val_acc: 0.8432\n",
      "Epoch 88/100\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.5994 - acc: 0.8466 - val_loss: 0.6777 - val_acc: 0.8230\n",
      "Epoch 89/100\n",
      "781/781 [==============================] - 28s 35ms/step - loss: 0.6017 - acc: 0.8460 - val_loss: 0.6156 - val_acc: 0.8500\n",
      "Epoch 90/100\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.5995 - acc: 0.8457 - val_loss: 0.6684 - val_acc: 0.8381\n",
      "Epoch 91/100\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 0.5982 - acc: 0.8472 - val_loss: 0.6052 - val_acc: 0.8543\n",
      "Epoch 92/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.5878 - acc: 0.8500 - val_loss: 0.6057 - val_acc: 0.8555\n",
      "Epoch 93/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.5923 - acc: 0.8489 - val_loss: 0.6038 - val_acc: 0.8508\n",
      "Epoch 94/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.5927 - acc: 0.8495 - val_loss: 0.5655 - val_acc: 0.8670\n",
      "Epoch 95/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.5952 - acc: 0.8478 - val_loss: 0.7018 - val_acc: 0.8252\n",
      "Epoch 96/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.5925 - acc: 0.8476 - val_loss: 0.6666 - val_acc: 0.8389\n",
      "Epoch 97/100\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.5862 - acc: 0.8497 - val_loss: 0.6944 - val_acc: 0.8275\n",
      "Epoch 98/100\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.5933 - acc: 0.8484 - val_loss: 0.6828 - val_acc: 0.8290\n",
      "Epoch 99/100\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.5906 - acc: 0.8486 - val_loss: 0.5936 - val_acc: 0.8526\n",
      "Epoch 100/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.5898 - acc: 0.8495 - val_loss: 0.6321 - val_acc: 0.8472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ad39d2ac8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensorflow-gpu)",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
